{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11add776-1e11-4884-a3bd-ef386d92e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers==4.34.0\" \"datasets[s3]==2.13.0\" \"sagemaker>=2.190.0\" \"gradio==3.50.2\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ccea204-4d17-42b6-b085-ea4af1faf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import tarfile\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.huggingface.model import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476f1ef-ea3d-4546-b54a-e4806fe89b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3267e73-1680-418e-826d-db0d7641a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compressed model URI; it can either be a fine-tuned model or a manually downloaded binary file of the model \n",
    "model_uri = 's3://sagemaker-eu-north-1-564976835481/huggingface-pytorch-training-2023-11-28-07-30-02-735/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462db14-4251-4607-b796-a690f3e20103",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_parts = model_uri.split(\"/\")  # => ['s3:', '', 'sagemakerbucketname', 'data', ...\n",
    "# bucket_name = url_parts[2]\n",
    "key = os.path.join(*url_parts[3:])\n",
    "filename = url_parts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c2869-9e85-49a5-87e9-515218433c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 object and client to download and uplaod files\n",
    "s3 = boto3.resource('s3')\n",
    "client = s3.meta.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc9fb2-2b69-4d82-9c09-ad37d7a9cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model from s3\n",
    "s3.Bucket(bucket).download_file(key, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b90e0a-76e7-43f5-b302-be4876ffa065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract compressed model.tar.gz\n",
    "os.makedirs('model_extracted', exist_ok=True)\n",
    "file = tarfile.open('model.tar.gz')\n",
    "file.extractall('model_extracted')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c7f9c-e4c2-4a4b-aba2-58470f2f9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy code folder which contains inference.py and requirement.txt in extracted folder of compressed model.tar.gz\n",
    "copy_tree(\"code/\", os.path.join('model_extracted', 'code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc36da-86ce-43f3-9dae-54427aa40bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename tag.gz model since we are going to compress new model and code with the same name\n",
    "!mv model.tar.gz model.tar.gz_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444a82c-fac8-46de-95f4-0c4848a06133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to create the model.tar.gz\n",
    "def compress(tar_dir=None, output_file=\"model.tar.gz\"):\n",
    "    parent_dir=os.getcwd()\n",
    "    os.chdir(tar_dir)\n",
    "    with tarfile.open(os.path.join(parent_dir, output_file), \"w:gz\") as tar:\n",
    "        for item in os.listdir('.'):\n",
    "            print(item)\n",
    "            tar.add(item, arcname=item)\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "compress(str('model_extracted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97738f-0bcf-4fbf-bc3a-0753604d705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload model.tar.gz to s3\n",
    "s3_model_uri=S3Uploader.upload(local_path=\"model.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/diffusion_dreambooth_fine_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d113a9-f902-4706-90a6-4fa7aec85589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,      # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version='4.28',  # transformers version used\n",
    "   pytorch_version='2.0',        # pytorch version used\n",
    "   py_version='py310',           # python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea54b33-bc4f-4b3d-9403-43a2a3ad351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33715125-03d5-4ec8-99ad-37219ac09a90",
   "metadata": {},
   "source": [
    "## Test Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f0e4c-3724-417a-afa9-b235d4709246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c9463-7b11-4515-89ca-da8b178ffb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "    base64_image = base64.b64decode(image_string)\n",
    "    buffer = BytesIO(base64_image)\n",
    "    return Image.open(buffer)\n",
    "\n",
    "# display PIL images as grid\n",
    "def display_images(images=None,columns=3, width=100, height=100):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e0ddb-a8b8-4f8e-9cd7-e128be412659",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_per_prompt = 3\n",
    "prompt = \"a photo of sks cat\"\n",
    "\n",
    "# run prediction\n",
    "response = predictor.predict(data={\n",
    "  \"inputs\": prompt,\n",
    "  \"num_images_per_prompt\" : num_images_per_prompt\n",
    "  }\n",
    ")\n",
    "\n",
    "# decode images\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "\n",
    "# visualize generation\n",
    "display_images(decoded_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
