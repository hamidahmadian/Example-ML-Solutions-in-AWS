{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9aca1e-5948-41f7-bf1e-8cca33474d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers==4.34.0\" \"datasets[s3]==2.13.0\" \"sagemaker>=2.190.0\" \"gradio==3.50.2\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259af93-e5c3-420f-8284-20ed3278ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker.huggingface import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c32d7-ddc5-4f2e-94fe-e7793ffb8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa859ac3-6239-405b-95b5-809e6a3cdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 object and client to download and uplaod files\n",
    "s3 = boto3.resource('s3')\n",
    "client = s3.meta.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb06b5-0023-40d3-b916-76b042a288cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define or get urls and addresses\n",
    "local_directory = '<LOCAL_PATH_TO_FOLDER_OF_YOUR_IMAGES>' # you can first upload your images into notebook panel and then from there to s3\n",
    "destination = 'training-diffusion'\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41a8f1-06f4-4973-9012-d73d64e16704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on above we can set a path in s3 for uploading our images there\n",
    "training_input_path = f's3://{sess.default_bucket()}/{destination}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10105022-188f-47ef-97ec-a9248b107035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_folder(local_directory, destination):\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            # construct the full local path\n",
    "            local_path = os.path.join(root, filename)\n",
    "            # construct the full Dropbox path\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            s3_path = os.path.join(destination, relative_path)\n",
    "            # relative_path = os.path.relpath(os.path.join(root, filename))\n",
    "            print('Searching \"%s\" in \"%s\"' % (s3_path, bucket))\n",
    "            try:\n",
    "                client.head_object(Bucket=bucket, Key=s3_path)\n",
    "                print(\"Path found on S3! Skipping %s...\" % s3_path)\n",
    "                # try:\n",
    "                # client.delete_object(Bucket=bucket, Key=s3_path)\n",
    "                # except:\n",
    "                # print(\"Unable to delete %s...\" % s3_path)\n",
    "            except:\n",
    "                print(\"Uploading %s...\" % s3_path)\n",
    "                client.upload_file(local_path, bucket, s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22169ce0-1de8-47b1-b762-36292a1f44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload images to s3\n",
    "upload_folder(local_directory, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e8a99-c342-4ce8-987b-f14e19a1a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after uploading either you can check by command here or by checking your s3 UI\n",
    "list(s3.Bucket(bucket).objects.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84152868-9dbb-4275-af80-83e7cd1793ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be some mistakes, especially in the initial attempts when working with S3. If you want to delete unnecessary files in S3:\n",
    "# s3.Object(bucket, 'key').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37887682-1791-4814-874a-93ae53eb2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use huggingface estimator so we can pass our args like below since aws doesn't work with action we have changed script or parameters here to handle\n",
    "hyperparameters = {\n",
    "    'pretrained_model_name_or_path': \"CompVis/stable-diffusion-v1-4\",          # pre-trained model\n",
    "    'instance_data_dir': '/opt/ml/input/data/training',                        # path where sagemaker will save training dataset in s3\n",
    "    'num_train_epochs': 1,                                                     # number of training epochs\n",
    "    'class_data_dir': '/opt/ml/input/data/class_data',                         # class images for prior preservation in s3\n",
    "    'train_batch_size': 1,                                                     # batch size for training\n",
    "    'gradient_accumulation_steps': 1,                                          # Number of updates steps to accumulate\n",
    "    'output_dir': '/opt/ml/model',                                             # output directory, where to save assets during training in s3\n",
    "    'use_8bit_adam': True,                                                     # by setting this we can train dreambooth on ml.g4dn.xlarge 16gb\n",
    "    'with_prior_preservation': True,                                           # avoid overfitting\n",
    "    'prior_loss_weight': 1.0,                                                  # weight in loss\n",
    "    'instance_prompt': \"a_photo_of_sks_cat\",                                   # underlined justified prompt (will be removed in script args handler)\n",
    "    'class prompt': \"a_photo_of_cat\",                                          # underlined justified class prompt\n",
    "    'resolu800 steps for trainingtion': 512,                                   # resolution\n",
    "    \"lr_scheduler\":\"constant\",                                                 # learning rate scheduler\n",
    "    'learning_rate': 5e-6,                                                     # learning rate\n",
    "    \"lr_warmup_steps\": 0,                                                      # warmup steps\n",
    "    'num_class_images': 200,                                                   # generate 200 images with class prompt\n",
    "    'max_train_steps': 800,                                                    # 800 steps for training\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc8f60-1ce3-4523-888a-e513d0961236",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='train_dreambooth.py',        # name of script inside scripts folder\n",
    "        source_dir='./scripts',                   # folder contains script to train and requirement.txt\n",
    "        instance_type='ml.g4dn.xlarge',           # instance type selected from training instances\n",
    "        instance_count=1,                         # number of instances \n",
    "        role=role,                                # IAM role which we defined it earlier\n",
    "        transformers_version = '4.28',            # the transformers version used in the training job\n",
    "        pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "        py_version           = 'py310',           # the python version used in the training job\n",
    "        disable_output_compression = True         # not compress output to save training time and cost\n",
    "        hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa1d67-5896-438e-ac9c-afe82a5eab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit({'training': training_input_path})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
