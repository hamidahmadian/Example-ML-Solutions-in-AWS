{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924fd88d-e7ce-4328-bf2f-a424014556d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.190.0\"  \"huggingface_hub\" \"opencv-python\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c74db12-5260-4af1-851c-7ce0a5d00260",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import tarfile\n",
    "import os\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "from distutils.file_util import copy_file\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9178576-0670-46a2-a625-9fb4070fb057",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::564976835481:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "sagemaker bucket: sagemaker-eu-north-1-564976835481\n",
      "sagemaker session region: eu-north-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0b917b-330b-4a28-adea-3e43bb0233a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_path = f\"SG161222/Realistic_Vision_V4.0_noVAE\"\n",
    "vae_model_path = f\"stabilityai/sd-vae-ft-mse\"\n",
    "image_encoder_path = f\"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
    "ip_ckpt = \"ip-adapter-faceid-plus_sd15.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c00b10-442f-4b85-8863-62b3d5bd16af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -drf model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52654eb5-d990-45e2-b879-8d663ff8c309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create model dir\n",
    "model_tar = Path(f\"model-{random.getrandbits(16)}\")\n",
    "model_tar.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809a95f7-7176-4cec-8297-3b3f3278f9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebafae9e0244e379d0dee6dadb1de0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['model-13382/SG161222/Realistic_Vision_V4.0_noVAE/.gitattributes',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/README.md',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/model.safetensors',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/unet/config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/unet/diffusion_pytorch_model.safetensors',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/special_tokens_map.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/tokenizer_config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/merges.txt',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/vocab.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/model_index.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = snapshot_download(repo_id=base_model_path, allow_patterns='text_encoder/*')\n",
    "# copy snapshot to model dir\n",
    "copy_tree(snapshot_dir, str(model_tar.joinpath(base_model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90c0c6c0-a577-4f03-aa43-c3ddd38b555a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605e573b8ba04793a425761aa9ecdefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['model-13382/SG161222/Realistic_Vision_V4.0_noVAE/.gitattributes',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/README.md',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/model.safetensors',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/unet/config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/unet/diffusion_pytorch_model.safetensors',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/special_tokens_map.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/tokenizer_config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/merges.txt',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/vocab.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/model_index.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = snapshot_download(repo_id=base_model_path, allow_patterns='unet/*')\n",
    "# copy snapshot to model dir\n",
    "copy_tree(snapshot_dir, str(model_tar.joinpath(base_model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "134ef388-e1b2-46e8-80b0-7e198ff70175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d66b02aa121445d853033cfcc73adf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['model-13382/SG161222/Realistic_Vision_V4.0_noVAE/.gitattributes',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/README.md',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/model.safetensors',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/unet/config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/unet/diffusion_pytorch_model.safetensors',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/special_tokens_map.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/tokenizer_config.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/merges.txt',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/vocab.json',\n",
       " 'model-13382/SG161222/Realistic_Vision_V4.0_noVAE/model_index.json']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = snapshot_download(repo_id=base_model_path, allow_patterns='tokenizer/*')\n",
    "# copy snapshot to model dir\n",
    "copy_tree(snapshot_dir, str(model_tar.joinpath(base_model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8d3157c-0aee-45cb-b941-5631402ff5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model-13382/SG161222/Realistic_Vision_V4.0_noVAE/model_index.json', 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = hf_hub_download(repo_id=base_model_path, filename=\"model_index.json\")\n",
    "# copy snapshot to model dir\n",
    "copy_file(snapshot_dir, str(model_tar.joinpath(base_model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f27ff7a-2b6d-46a4-a55a-2d1d1744779e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2308c5aedbc34ed49a61f4389e74895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['model-13382/stabilityai/sd-vae-ft-mse/config.json',\n",
       " 'model-13382/stabilityai/sd-vae-ft-mse/README.md',\n",
       " 'model-13382/stabilityai/sd-vae-ft-mse/.gitattributes',\n",
       " 'model-13382/stabilityai/sd-vae-ft-mse/diffusion_pytorch_model.safetensors',\n",
       " 'model-13382/stabilityai/sd-vae-ft-mse/diffusion_pytorch_model.bin']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = snapshot_download(repo_id=vae_model_path)\n",
    "# copy snapshot to model dir\n",
    "copy_tree(snapshot_dir, str(model_tar.joinpath(vae_model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72955c4e-aadd-4de2-9996-e94ec2b8e0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df993dc04c74f6a95ecf0278139650b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/.gitattributes',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/config.json',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/README.md',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/open_clip_config.json',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/merges.txt',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/special_tokens_map.json',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/preprocessor_config.json',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/tokenizer_config.json',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/tokenizer.json',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/vocab.json',\n",
       " 'model-13382/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/model.safetensors']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = snapshot_download(repo_id=image_encoder_path, allow_patterns=['config.json', 'model.safetensors'])\n",
    "# copy snapshot to model dir\n",
    "copy_tree(snapshot_dir, str(model_tar.joinpath(image_encoder_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bdc7f56-4a03-40e8-aaaa-c850e44cf313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model-13382/ip-adapter-faceid-plus_sd15.bin', 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = hf_hub_download(repo_id=\"h94/IP-Adapter-FaceID\", filename=ip_ckpt)\n",
    "# copy snapshot to model dir\n",
    "copy_file(snapshot_dir, str(model_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48078aa8-5a5e-491b-b95f-26b963a891b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-13382/code/pipelines/diffusion_pipelines.py',\n",
       " 'model-13382/code/pipelines/__init__.py',\n",
       " 'model-13382/code/.ipynb_checkpoints/inference-checkpoint.py',\n",
       " 'model-13382/code/.ipynb_checkpoints/requirements-checkpoint.txt',\n",
       " 'model-13382/code/inference.py',\n",
       " 'model-13382/code/requirements.txt',\n",
       " 'model-13382/code/__init__.py',\n",
       " 'model-13382/code/loaders/ip_adapter_face_plus.py',\n",
       " 'model-13382/code/loaders/__init__.py',\n",
       " 'model-13382/code/helper/nn_modules.py',\n",
       " 'model-13382/code/helper/__init__.py']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_tree('Example-ML-Solutions-in-AWS/FaceEditorInAWS/code/', str(model_tar.joinpath('code')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d0f67a3-006f-44e1-9048-36935187612d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/pipelines/\n",
      "code/pipelines/diffusion_pipelines.py\n",
      "code/pipelines/__init__.py\n",
      "code/.ipynb_checkpoints/\n",
      "code/.ipynb_checkpoints/inference-checkpoint.py\n",
      "code/.ipynb_checkpoints/requirements-checkpoint.txt\n",
      "code/inference.py\n",
      "code/requirements.txt\n",
      "code/__init__.py\n",
      "code/loaders/\n",
      "code/loaders/ip_adapter_face_plus.py\n",
      "code/loaders/__init__.py\n",
      "code/helper/\n",
      "code/helper/nn_modules.py\n",
      "code/helper/__init__.py\n",
      "ip-adapter-faceid-plus_sd15.bin\n",
      "laion/\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/open_clip_config.json\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/preprocessor_config.json\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/special_tokens_map.json\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/README.md\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/tokenizer.json\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/.gitattributes\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/config.json\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/merges.txt\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/vocab.json\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/model.safetensors\n",
      "laion/CLIP-ViT-H-14-laion2B-s32B-b79K/tokenizer_config.json\n",
      "SG161222/\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/README.md\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/unet/\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/unet/config.json\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/unet/diffusion_pytorch_model.safetensors\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/.gitattributes\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/config.json\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/text_encoder/model.safetensors\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/model_index.json\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/special_tokens_map.json\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/merges.txt\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/vocab.json\n",
      "SG161222/Realistic_Vision_V4.0_noVAE/tokenizer/tokenizer_config.json\n",
      "stabilityai/\n",
      "stabilityai/sd-vae-ft-mse/\n",
      "stabilityai/sd-vae-ft-mse/README.md\n",
      "stabilityai/sd-vae-ft-mse/diffusion_pytorch_model.bin\n",
      "stabilityai/sd-vae-ft-mse/.gitattributes\n",
      "stabilityai/sd-vae-ft-mse/config.json\n",
      "stabilityai/sd-vae-ft-mse/diffusion_pytorch_model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!cd {str(model_tar)} && tar zcvf ../model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7895b359-2954-47a2-88f5-08c6aa69fb76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # helper to create the model.tar.gz\n",
    "# def compress(tar_dir=None,output_file=\"model.tar.gz\"):\n",
    "#     parent_dir=os.getcwd()\n",
    "#     os.chdir(tar_dir)\n",
    "#     with tarfile.open(os.path.join(parent_dir, output_file), \"w:gz\") as tar:\n",
    "#         for item in os.listdir('.'):\n",
    "#             print(item)\n",
    "#             tar.add(item, arcname=item)\n",
    "#     os.chdir(parent_dir)\n",
    "\n",
    "# compress(str(model_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3060587e-5d2c-435b-8d99-c7274462acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-eu-north-1-564976835481/face_editor/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# upload model.tar.gz to s3\n",
    "s3_model_uri=S3Uploader.upload(local_path=\"model.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/face_editor\")\n",
    "\n",
    "print(f\"model uploaded to: {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9672d318-db5a-478c-9907-f091ac36ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,      # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version='4.28',  # transformers version used\n",
    "   pytorch_version='2.0',        # pytorch version used\n",
    "   py_version='py310',           # python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d69e131-9f01-4a47-899b-bd35f60b3544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c160c-f75a-4ee7-a93a-0be6cf1d3590",
   "metadata": {},
   "source": [
    "# Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bcf3c4-62a5-4d60-a4d2-f5a40da0848e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import cv2\n",
    "import boto3\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "    base64_image = base64.b64decode(image_string)\n",
    "    buffer = BytesIO(base64_image)\n",
    "    return Image.open(buffer)\n",
    "\n",
    "# display PIL images as grid\n",
    "def display_images(images=None,columns=3, width=100, height=100):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18ee129-a81b-40e0-8642-ceeff0c37d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buffered = BytesIO()\n",
    "Image.open(\"samples/Screenshot from 2024-02-09 13-53-24.png\").save(buffered, format=\"PNG\")\n",
    "image_string = base64.b64encode(buffered.getvalue()).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd1dcdff-8b0e-48dd-a593-f79757d41abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data={\n",
    "    \"prompt\":\"a beautiful girl , high quality, 8k\",\n",
    "    \"image\": image_string,\n",
    "    \"num_inference_steps\":30,\n",
    "    \"num_images_per_prompt\":4\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594f45cb-8baa-4719-8cfb-ab1371c4ad1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if predictor is not here then you may call your endpoint through name\n",
    "is_predictor_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f16a955-656f-4e89-9291-b21fd5bc9809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run prediction\n",
    "if is_predictor_loaded:\n",
    "    response = predictor.predict(data = data)\n",
    "else:\n",
    "    client = boto3.client(\"sagemaker-runtime\")\n",
    "    payload = json.dumps(data)\n",
    "    endpoint_result = client.invoke_endpoint(\n",
    "        EndpointName=\"huggingface-pytorch-inference-2024-02-09-12-13-11-335\",\n",
    "        ContentType=\"application/json\",\n",
    "        Body=payload, )\n",
    "    response = eval(endpoint_result[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd567885-9afc-4494-92f3-e4c4eb181017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decode images\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "\n",
    "# visualize generation\n",
    "display_images(decoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a5b2501-5b03-4410-8247-4f7cc0d545da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b55188-6684-4d57-9c47-a10d6ff88d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d014f6-ef3f-4901-9f82-f61a58c12650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
